C:\Users\kamen\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\optim\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
learning rate 0.0002000 -> 0.0002000
(epoch: 1, iters: 100, time: 0.225, data: 0.059) G_GAN: 23.477 G_L1: 0.149 D_real: 29.177 D_fake: 26.774
(epoch: 1, iters: 200, time: 0.199, data: 0.006) G_GAN: 22.132 G_L1: 0.018 D_real: 24.858 D_fake: 23.156
(epoch: 1, iters: 300, time: 0.180, data: 0.011) G_GAN: 14.913 G_L1: 0.020 D_real: 22.755 D_fake: 16.231
(epoch: 1, iters: 400, time: 0.222, data: 0.012) G_GAN: 15.673 G_L1: 0.022 D_real: 16.251 D_fake: 15.549
(epoch: 1, iters: 500, time: 0.199, data: 0.012) G_GAN: 10.537 G_L1: 0.032 D_real: 12.356 D_fake: 10.692
(epoch: 1, iters: 600, time: 0.206, data: 0.015) G_GAN: 6.088 G_L1: 0.038 D_real: 7.746 D_fake: 6.756
(epoch: 1, iters: 700, time: 0.228, data: 0.013) G_GAN: 10.314 G_L1: 0.000 D_real: 12.061 D_fake: 11.158
(epoch: 1, iters: 800, time: 0.184, data: 0.010) G_GAN: 6.407 G_L1: 0.032 D_real: 12.028 D_fake: 5.945
(epoch: 1, iters: 900, time: 0.230, data: 0.017) G_GAN: 9.447 G_L1: 0.161 D_real: 13.283 D_fake: 9.316
(epoch: 1, iters: 1000, time: 0.242, data: 0.008) G_GAN: 8.759 G_L1: 0.188 D_real: 8.221 D_fake: 8.655
End of epoch 1 / 10 	 Time Taken: 147 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 2, iters: 100, time: 0.244, data: 0.008) G_GAN: 1.136 G_L1: 0.148 D_real: 1.534 D_fake: 1.319
(epoch: 2, iters: 200, time: 0.232, data: 0.006) G_GAN: 3.049 G_L1: 0.017 D_real: 3.865 D_fake: 3.065
(epoch: 2, iters: 300, time: 0.223, data: 0.013) G_GAN: 2.933 G_L1: 0.020 D_real: 4.092 D_fake: 2.667
(epoch: 2, iters: 400, time: 0.237, data: 0.007) G_GAN: 3.485 G_L1: 0.022 D_real: 3.317 D_fake: 2.629
(epoch: 2, iters: 500, time: 0.205, data: 0.007) G_GAN: 1.702 G_L1: 0.032 D_real: 2.250 D_fake: 1.868
(epoch: 2, iters: 600, time: 0.196, data: 0.009) G_GAN: 0.996 G_L1: 0.038 D_real: 1.042 D_fake: 1.263
(epoch: 2, iters: 700, time: 0.223, data: 0.009) G_GAN: 2.811 G_L1: 0.000 D_real: 4.241 D_fake: 3.326
(epoch: 2, iters: 800, time: 0.196, data: 0.014) G_GAN: 1.848 G_L1: 0.032 D_real: 2.130 D_fake: 1.319
(epoch: 2, iters: 900, time: 0.224, data: 0.016) G_GAN: 3.566 G_L1: 0.161 D_real: 2.766 D_fake: 2.815
(epoch: 2, iters: 1000, time: 0.226, data: 0.010) G_GAN: 2.416 G_L1: 0.188 D_real: 1.986 D_fake: 2.089
End of epoch 2 / 10 	 Time Taken: 146 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 3, iters: 100, time: 0.189, data: 0.014) G_GAN: 0.405 G_L1: 0.148 D_real: 0.402 D_fake: 0.475
(epoch: 3, iters: 200, time: 0.186, data: 0.016) G_GAN: 1.146 G_L1: 0.017 D_real: 1.491 D_fake: 1.096
(epoch: 3, iters: 300, time: 0.210, data: 0.020) G_GAN: 1.209 G_L1: 0.020 D_real: 1.075 D_fake: 1.118
(epoch: 3, iters: 400, time: 0.201, data: 0.012) G_GAN: 1.800 G_L1: 0.022 D_real: 0.484 D_fake: 1.026
(epoch: 3, iters: 500, time: 0.208, data: 0.007) G_GAN: 0.941 G_L1: 0.032 D_real: 0.741 D_fake: 0.777
(epoch: 3, iters: 600, time: 0.195, data: 0.013) G_GAN: 0.531 G_L1: 0.038 D_real: 0.331 D_fake: 0.709
(epoch: 3, iters: 700, time: 0.243, data: 0.007) G_GAN: 3.803 G_L1: 0.000 D_real: 3.026 D_fake: 2.127
(epoch: 3, iters: 800, time: 0.245, data: 0.006) G_GAN: 1.269 G_L1: 0.032 D_real: 0.924 D_fake: 0.643
(epoch: 3, iters: 900, time: 0.237, data: 0.008) G_GAN: 2.255 G_L1: 0.161 D_real: 1.191 D_fake: 1.357
(epoch: 3, iters: 1000, time: 0.244, data: 0.009) G_GAN: 1.390 G_L1: 0.188 D_real: 0.906 D_fake: 1.047
End of epoch 3 / 10 	 Time Taken: 147 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 4, iters: 100, time: 0.229, data: 0.008) G_GAN: 0.320 G_L1: 0.148 D_real: 0.198 D_fake: 0.476
(epoch: 4, iters: 200, time: 0.169, data: 0.008) G_GAN: 0.759 G_L1: 0.017 D_real: 0.956 D_fake: 0.762
(epoch: 4, iters: 300, time: 0.207, data: 0.010) G_GAN: 0.713 G_L1: 0.020 D_real: 0.375 D_fake: 0.856
(epoch: 4, iters: 400, time: 0.203, data: 0.009) G_GAN: 1.350 G_L1: 0.022 D_real: 0.263 D_fake: 0.493
(epoch: 4, iters: 500, time: 0.234, data: 0.011) G_GAN: 0.843 G_L1: 0.032 D_real: 0.327 D_fake: 0.528
(epoch: 4, iters: 600, time: 0.238, data: 0.007) G_GAN: 0.501 G_L1: 0.038 D_real: 0.162 D_fake: 0.501
(epoch: 4, iters: 700, time: 0.212, data: 0.007) G_GAN: 4.069 G_L1: 0.000 D_real: 2.255 D_fake: 1.291
(epoch: 4, iters: 800, time: 0.206, data: 0.018) G_GAN: 1.104 G_L1: 0.032 D_real: 0.716 D_fake: 0.404
(epoch: 4, iters: 900, time: 0.188, data: 0.013) G_GAN: 1.740 G_L1: 0.161 D_real: 0.722 D_fake: 0.883
(epoch: 4, iters: 1000, time: 0.201, data: 0.012) G_GAN: 1.053 G_L1: 0.188 D_real: 0.526 D_fake: 0.667
End of epoch 4 / 10 	 Time Taken: 147 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 5, iters: 100, time: 0.222, data: 0.016) G_GAN: 0.324 G_L1: 0.148 D_real: 0.135 D_fake: 0.497
(epoch: 5, iters: 200, time: 0.179, data: 0.009) G_GAN: 0.601 G_L1: 0.017 D_real: 0.628 D_fake: 0.651
(epoch: 5, iters: 300, time: 0.222, data: 0.026) G_GAN: 0.541 G_L1: 0.020 D_real: 0.200 D_fake: 0.750
(epoch: 5, iters: 400, time: 0.227, data: 0.009) G_GAN: 1.122 G_L1: 0.022 D_real: 0.214 D_fake: 0.302
(epoch: 5, iters: 500, time: 0.230, data: 0.010) G_GAN: 0.892 G_L1: 0.032 D_real: 0.319 D_fake: 0.498
(epoch: 5, iters: 600, time: 0.233, data: 0.005) G_GAN: 0.434 G_L1: 0.038 D_real: 0.108 D_fake: 0.354
(epoch: 5, iters: 700, time: 0.238, data: 0.008) G_GAN: 3.104 G_L1: 0.000 D_real: 1.707 D_fake: 1.204
(epoch: 5, iters: 800, time: 0.232, data: 0.007) G_GAN: 0.994 G_L1: 0.032 D_real: 0.559 D_fake: 0.256
(epoch: 5, iters: 900, time: 0.242, data: 0.007) G_GAN: 1.599 G_L1: 0.161 D_real: 0.480 D_fake: 0.618
(epoch: 5, iters: 1000, time: 0.247, data: 0.010) G_GAN: 0.936 G_L1: 0.188 D_real: 0.351 D_fake: 0.515
saving the latest model (epoch 5, total_iters 5000)
