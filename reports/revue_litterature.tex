% \documentclass[twocolumn]{article}
\documentclass[]{article}
\usepackage[left=20mm, right=20mm, top=20mm, bottom=20mm]{geometry}
\usepackage{lipsum}  % This package generates filler text.
\usepackage{amsmath} % For mathematical formulas.
\usepackage{graphicx} % For including figures.
\usepackage{authblk} % For author and affiliation blocks.
\usepackage[english]{babel}
\usepackage{graphicx} % Required for inserting images
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{multicol}
\usepackage{svg}
\usepackage{flushend}

\usepackage[
backend=biber,
style=alphabetic,
sorting=ydnt
]{biblatex} %Imports biblatex package
\addbibresource{reports/references.bib} %Import the bibliography file
\setlength\bibitemsep{0.5\baselineskip}

\hypersetup{
    colorlinks=true,
    urlcolor=blue,
    linkcolor=black
}

\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\proofend}{\hfill $\square$}
\newcommand{\deltach}{\hat{\delta}}

\title{\textbf{IFT 3710 - Team "GANg"} \\ 
\textbf{Data Augmentation for Cell Segmentation}}

\author[1]{Bio Samir Gbian}
\author[1]{Kamen Damov}
\author[1]{Simon Langlois}
\author[1]{Guillaume Genois}
\author[1]{Johann Sourou}
\affil{Departement of Computer Science and Operations Research}
\affil[1]{University of Montreal}

\begin{document}
\maketitle

\href{https://github.com/KamenDamov/IFT3710-Advanced-Project-in-ML-AI}{GitHub Code Repository}

Microscopy image segmentation, crucial in biomedical analysis, is often tedious and error-prone when performed manually. Our project compares two automation approaches: data augmentation using GANs to optimize a U-Net model \cite{majurski2020cell}, and transfer learning with pre-trained models (Cellpose, Stardist) \cite{park2022use}. This review examines segmentation techniques, focusing on Generative Adversarial Networks (GANs) and transfer learning, as well as architectures such as U-Net, Mask R-CNN, Cellpose, and Stardist.

\section{Litterature Review}
\subsection{Cell segmentation (SOTA and challenges)}

Advancements in machine learning have significantly enhanced medical image segmentation. The introduction of U-Net in 2015 marked a pivotal moment, utilizing convolutional neural networks for medical segmentation tasks. In 2017, Mask R-CNN further refined this approach by integrating object detection with segmentation capabilities. By 2018, StarDist introduced a novel method representing objects as star-shaped polygons, effectively handling irregularly shaped cells. In 2021, Cellpose emerged as a versatile solution, outperforming models like StarDist and Mask R-CNN with an average precision of 0.82. The latest advancement, Cellpose3 (2025), incorporates image restoration techniques, enhancing segmentation performance under challenging experimental conditions. Notably, MEDIAR, the winner of the NeurIPS 2022 Grand Challenge, innovated by replacing traditional convolutional neural networks with visual transformer blocks within a U-Net architecture, achieving a remarkable F1-score of 0.8537 on the test set.

The MEDIAR paper \cite{pmlr-v212-lee23a} mentions various approaches to data augmentation and semi-supervised learning (Consistency Regularization, Reconstruction Error, Pseudo Labeling), but they failed to improve the model's performance, so only supervised training on the labeled data was used in the end.

The NeurIPS Challenge review paper \cite{NeurIPS-CellSeg} calls it "an open
question how to effectively use unlabeled data to boost cell segmentation performance." Our goal for this project is to investigate this problem, employing GANs towards semi-supervised training for cell segmentation.

\subsection{Semantic Segmentation data augmentation using GANs}
Recent advances in GAN-based data augmentation have shown significant improvements in semantic segmentation by generating synthetic training data, addressing challenges such as limited labeled data, class imbalance, and domain adaptation. Liu et al. [96] proposed a pixel-level data augmentation approach, where GANs are trained to generate new training images, leading to a 1.3\% to 2.1\% improvement in segmentation accuracy, particularly for underrepresented classes. Choi et al. [97] introduced self-ensembling with GAN-based data augmentation, which enhances domain adaptation by synthesizing labeled training data, reducing the performance gap between synthetic and real-world datasets. Che et al. [98] explored controllable generative models to create diverse labeled datasets, integrating class-prompt appending to ensure a more balanced distribution of segmentation labels. Wang et al. [95] leveraged high-resolution conditional GANs (Pix2PixHD) to synthesize realistic images from semantic label maps, demonstrating that conditional GANs improve both image quality and segmentation model robustness. Sandfort et al. [101] applied CycleGANs for medical image segmentation, showing that GAN-generated data significantly enhances model generalizability, particularly in out-of-distribution CT scans, with a Dice score improvement from 0.09 to 0.66. These studies demonstrate the effectiveness of GANs in generating labeled data for semantic segmentation, either by creating new segmentation masks or synthesizing images conditioned on masks, thereby reducing the reliance on manual annotation while enhancing segmentation performance.

\subsection{Transfer Learning}
Pani and Chawla (2024) demonstrated that a hybrid approach combining transfer learning and self-supervised learning could significantly refine brain tumor segmentation, suggesting that similar methods could be beneficial for cellular segmentation. Aghiles et al. (2023) successfully applied transfer learning for blood cell segmentation and counting, confirming the robustness of this approach in various clinical scenarios. In the specific field of cellular segmentation, Auto-CSC (Zhan et al., 2022) is a framework designed to leverage the transfer of a pre-trained model to efficiently segment and count cells, showing that this technique can compensate for the lack of manual annotations. Saleem et al. (2022) merged multiple pre-trained models to achieve precise leukocyte segmentation, illustrating the potential of transfer learning in handling complex cellular structures. Finally, the review by Cheplygina et al. (2019) confirms the value of combining transfer learning with semi-supervised methods to mitigate the scarcity of annotated data in medical imaging. These studies demonstrate that by integrating pre-trained models such as Cellpose or Stardist into our project, it is possible to optimize individual cell segmentation to compensate for a small volume of labeled data.
\subsection{Multimodal data augmentation}
Semantic segmentation in highly unlabeled datasets can be improved using multimodal augmentation, few-shot learning, and data augmentation techniques. Recent studies have explored integrating textual descriptions with visual data to enhance segmentation accuracy. Hsieh et al. (2024) introduced a graph-based captioning approach to enrich image representations with structured textual context (Hsieh et al., 2024). Wang et al. (2023) proposed MetaSegNet, which leverages metadata-based textual prompts for improved segmentation (Wang et al., 2023). Few-shot learning methods, such as the framework by Li et al. (2024), reduce reliance on labeled data through unsupervised meta-training (Li et al., 2024). Meanwhile, augmentation techniques like ChessMix (Pereira \& dos Santos, 2021) and transformations surveyed by Shorten et al. (2021) enhance data diversity and model robustness (Pereira \& dos Santos, 2021, Shorten et al., 2021). The combination of these methods enables more effective segmentation models in data-scarce environments.

\newpage
\onecolumn
\section*{References (given)}

\nocite{*}

 %Prints NeurIPS bibliography
\printbibliography[heading=subbibintoc,keyword=neurips,title={NeurIPS 2022}]
%Prints suggested SOTA bibliography
\printbibliography[heading=subbibintoc,keyword=sota,title={SOTA Image Segmentation Methods \& Surveys}] 
%Prints suggested architecture papers
\printbibliography[heading=subbibintoc,keyword=architecture,title={Neural Network Architecture}]


%Prints un-labeled remainder
\printbibliography[heading=bibintoc,notkeyword=neurips,notkeyword=sota,notkeyword=architecture,notkeyword=gans,notkeyword=augmentation,notkeyword=transferlearning,title={References (found)}]

%Prints GANs bibliography
\printbibliography[heading=subbibintoc,keyword=gans,title={Generative Adversarial Networks}] 

%Prints Transfer Learning bibliography
\printbibliography[heading=subbibintoc,keyword=transferlearning,title={Transfer learning}] 

%Prints Data Augmentation bibliography
\printbibliography[heading=subbibintoc,keyword=augmentation,title={Multimodal Data Augmentation}] 
\end{document}