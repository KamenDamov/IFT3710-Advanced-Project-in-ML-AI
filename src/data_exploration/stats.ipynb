{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import zipfile\n",
    "import os\n",
    "from explore import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, shutil\n",
    "\n",
    "# Load from the .pkl file\n",
    "with open(\"../data_preprocess/modalities/modalities.pkl\", \"rb\") as f:  # \"rb\" means read binary\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "len([y for x in loaded_data.values() for y in x])  # Check the sum of the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"../../data\"\n",
    "zenodo = ZenodoNeurIPS('/zenodo')\n",
    "unzip_dataset(dataroot + \"/raw\", folder= zenodo.root + \"/\")\n",
    "files_by_type = list_dataset(dataroot + \"/raw\", folder= zenodo.root + \"/\")\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "plt.bar(IMAGE_TYPES, [len(files_by_type[type]) for type in IMAGE_TYPES], label='Files')\n",
    "plt.title(\"File types in dataset\")\n",
    "plt.xlabel(\"File type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_types = {cat:{type:set() for type in IMAGE_TYPES} for cat in [LABELED, MASK, UNLABELED, SYNTHETIC]}\n",
    "\n",
    "for type in IMAGE_TYPES:\n",
    "    for filepath in files_by_type[type]:\n",
    "        file_types[zenodo.categorize(filepath)][type].add(filepath)\n",
    "\n",
    "for cat in [LABELED, MASK, UNLABELED, SYNTHETIC]:\n",
    "    types = file_types[cat]\n",
    "    counts = {k:len(s) for k, s in types.items()}\n",
    "    print(cat, sum(counts.values()), counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(IMAGE_TYPES))  # the label locations\n",
    "width = 0.25\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "\n",
    "index = 0\n",
    "for cat, data in file_types.items():\n",
    "    plt.bar(x + index * width, [len(data[key]) for key in IMAGE_TYPES], width, label=cat)\n",
    "    index += 1\n",
    "    \n",
    "plt.title(\"File types in dataset\")\n",
    "plt.xlabel(\"File type\")\n",
    "plt.xticks(x + width, IMAGE_TYPES)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "maskTensor = load_raw_mask(dataroot + \"/raw\" + \"/cellpose/train_cyto2/758_masks.png\")\n",
    "#io.imread(dataroot + \"/raw\" + \"/zenodo/Training-labeled/labels/cell_00001_label.tiff\").shape\n",
    "#maskTensor.shape, len(np.unique(maskTensor)), np.unique(maskTensor), (maskTensor == 0).sum()\n",
    "labels = set(np.unique(maskTensor))\n",
    "for i in range(0, 65535):\n",
    "    if i not in labels:\n",
    "        print(i, \"not in labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_frame(mask_path, meta_path):\n",
    "    tensor = cv2.imread(mask_path)\n",
    "    df = pd.read_csv(meta_path)\n",
    "    width = df['Right'].max()\n",
    "    height = df['Bottom'].max()\n",
    "    assert tensor.shape[0] == height\n",
    "    assert tensor.shape[1] == width\n",
    "    area = df['Area'].sum()\n",
    "    assert (width * height) == area\n",
    "    assert area != 0\n",
    "    for index in range(len(df)):\n",
    "        bdf = df.iloc[index]\n",
    "        sanity_check_box(width, height, bdf)\n",
    "\n",
    "def sanity_check_box(width, height, bdf):\n",
    "        bwidth = bdf['Right'] - bdf['Left']\n",
    "        bheight = bdf['Bottom'] - bdf['Top']\n",
    "        barea = bwidth * bheight\n",
    "        #print(width, height, bdf)\n",
    "        assert 0 <= bwidth <= width\n",
    "        assert 0 <= bheight <= height\n",
    "        assert 0 <= bdf['Area'] <= barea\n",
    "        assert 0 <= bdf['Left'] <= width\n",
    "        assert 0 <= bdf['Right'] <= width\n",
    "        assert 0 <= bdf['Top'] <= height\n",
    "        assert 0 <= bdf['Bottom'] <= height\n",
    "\n",
    "class DataLabels2(DataLabels):\n",
    "    # P(width, height) = width * height / maxArea\n",
    "    # P(width, height | area) = \n",
    "    def randboxbad4(self, random):\n",
    "        rwidth = int(random.triangular(0, self.width+1, self.width+1))\n",
    "        rheight = int(random.triangular(0, self.height+1, self.height+1))\n",
    "        left = random.randint(0, self.width+1 - rwidth)\n",
    "        right = left + rwidth\n",
    "        top = random.randint(0, self.height+1 - rheight)\n",
    "        bottom = top + rheight\n",
    "        return self.dictbox([left, top, right, bottom])\n",
    "\n",
    "    def randboxu(self, random):\n",
    "        # area = height**2 * ratio\n",
    "        ratio = self.width/self.height if self.height else 1\n",
    "        rarea = random.randint(0, self.width * self.height + 1)\n",
    "        rheight = int(np.sqrt(rarea / ratio))\n",
    "        rwidth = int(rheight * ratio)\n",
    "        left = random.randint(0, self.width+1 - rwidth)\n",
    "        right = left + rwidth\n",
    "        top = random.randint(0, self.height+1 - rheight)\n",
    "        bottom = top + rheight\n",
    "        return self.dictbox([left, top, right, bottom])\n",
    "\n",
    "    def randboxbad3(self, random, rsize=None):\n",
    "        rwidth = rsize or random.randint(0, self.width+1)\n",
    "        rheight = rsize or random.randint(0, self.height+1)\n",
    "        left = random.randint(0, self.width+1 - rwidth)\n",
    "        right = left + rwidth\n",
    "        top = random.randint(0, self.height+1 - rheight)\n",
    "        bottom = top + rheight\n",
    "        return self.dictbox([left, top, right, bottom])\n",
    "    \n",
    "    def randboxbad2(self, random):\n",
    "        x1, x2 = random.randint(0, self.width+1), random.randint(0, self.width+1)\n",
    "        left, right = min(x1, x2), max(x1, x2)\n",
    "        y1, y2 = random.randint(0, self.height+1), random.randint(0, self.height+1)\n",
    "        top, bottom = min(y1, y2), max(y1, y2)\n",
    "        return self.dictbox([left, top, right, bottom])\n",
    "    \n",
    "    def randboxbad(self, random):\n",
    "        left = random.randint(0, self.width+1)\n",
    "        right = random.randint(left, self.width+1)\n",
    "        top = random.randint(0, self.height+1)\n",
    "        bottom = random.randint(top, self.height+1)\n",
    "        return self.dictbox([left, top, right, bottom])\n",
    "    \n",
    "    def randbox(self, random, df):\n",
    "        left = random.randint(0, df['Left']+1)\n",
    "        right = random.randint(df['Right'], self.width+1)\n",
    "        top = random.randint(0, df['Top']+1)\n",
    "        bottom = random.randint(df['Bottom'], self.height+1)\n",
    "        return self.dictbox([left, top, right, bottom])\n",
    "\n",
    "    def randobject(self, random):\n",
    "        weights = self.df['Area'].sum() / self.df['Area']\n",
    "        weights = list(weights / weights.sum())\n",
    "        # sample an integer according to given weights\n",
    "        return random.choice(len(self.df), p=weights)\n",
    "    \n",
    "    def randscalar(self, random):\n",
    "        x = random.beta(0.5, 0.5)\n",
    "        y = random.beta(0.5, 0.5)\n",
    "        sx = random.beta(2, 2)\n",
    "        sy = random.beta(2, 2)\n",
    "        return [x, y, sx, sy]\n",
    "\n",
    "dataset = list(DataSet(dataroot))\n",
    "random = np.random.RandomState()\n",
    "empty = DataLabels2.dictbox(None, [0, 0, 0, 0])\n",
    "print(empty)\n",
    "\n",
    "for sample in dataset[1:2]:\n",
    "    labels = DataLabels2(sample.meta_frame)\n",
    "    samples = {key:[] for key in empty.keys()}\n",
    "    tsamples = np.zeros((sample.height, sample.width))\n",
    "    osamples = [] #[0] * 27\n",
    "\n",
    "    print(sample.width, sample.height, sample.meta_frame)\n",
    "    for _ in tqdm(range(sample.df['Objects'] * 100)):\n",
    "        #sanity_check_frame(sample.bw_mask, sample.meta_frame)\n",
    "        box = labels.randboxsmart(random)#, rwidth=256, rheight=256)\n",
    "        crop = box#labels.dictbox(box)\n",
    "        #print(sample.df['Width'], sample.df['Height'], crop)\n",
    "        sanity_check_box(sample.width, sample.height, crop)\n",
    "        for key in crop.keys():\n",
    "            samples[key].append(crop[key])\n",
    "        tensor = load_image(sample.raw_mask)\n",
    "        tsamples[crop['Top']:crop['Bottom'], crop['Left']:crop['Right']] += 1\n",
    "        #tensor = tensor[crop['Top']:crop['Bottom'], crop['Left']:crop['Right']]\n",
    "        #tif.imshow(tensor, show = True)\n",
    "        #osamples += list(np.unique(tensor))\n",
    "    \n",
    "    #tsamples = np.log(tsamples)\n",
    "    timg = Image.fromarray((tsamples / tsamples.max() * 255).astype('uint8'))\n",
    "    timg.save(\"samples.png\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    #plt.hist(osamples, bins=np.max(osamples)+1, label='Objects')\n",
    "    #plt.bar(list(range(20)), odf['Area'], label='Objects2')\n",
    "    #plt.hist(tsamples.flatten(), bins=100)\n",
    "    plt.hist(samples['Area'], bins=100)\n",
    "    #plt.hist([-np.log2(n[2]) for n in numbers], bins=100)\n",
    "    plt.title(\"Frequency of samples\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    #plt.xticks([2.0 ** x for x in range(8)])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tsamples = np.log(tsamples)\n",
    "timg = Image.fromarray((tsamples / tsamples.max() * 255).astype('uint8'))\n",
    "timg.save(\"samples.png\")\n",
    "\n",
    "print(sample.meta_frame)\n",
    "odf = pd.read_csv(sample.meta_frame)\n",
    "print(len(np.unique(osamples)), np.unique(osamples))\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(osamples, bins=np.max(osamples)+1, label='Objects')\n",
    "#plt.bar(list(range(20)), odf['Area'], label='Objects2')\n",
    "#plt.hist(tsamples.flatten(), bins=100)\n",
    "#plt.hist(samples['Area'], bins=100)\n",
    "#plt.hist([-np.log2(n[2]) for n in numbers], bins=100)\n",
    "plt.title(\"Frequency of samples\")\n",
    "plt.xlabel(\"Value\")\n",
    "#plt.xticks([2.0 ** x for x in range(8)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = \"/zenodo/Testing/Public/labels/OpenTest_006_label\"\n",
    "sample = \"/zenodo/Training-labeled/labels/cell_00854_label\"\n",
    "maskDF = pd.read_csv(dataroot + \"/processed\" + sample + \".csv\")\n",
    "save_hue_mask(dataroot + \"/raw\", dataroot + \"/processed\", sample + \".tiff\", maskDF)\n",
    "maskDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(dataroot)\n",
    "data_map = dataset.df #[dataset.df['Synthetic'] != True]\n",
    "\n",
    "print(\"Valeurs aberrantes?\")\n",
    "data_map[data_map[\"Objects\"] > 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, segmentation, morphology, exposure\n",
    "from tqdm import tqdm\n",
    "from monai.data import PILReader\n",
    "\n",
    "exts = set()\n",
    "shapes = set()\n",
    "dataset = list(zip(data_map[\"Path\"], data_map[\"Mask\"]))[180:]\n",
    "for filepath, maskpath in tqdm(dataset):\n",
    "    if \"WSI\" in filepath: continue\n",
    "    folder, name, ext = split_filepath(filepath)\n",
    "    exts.add(ext)\n",
    "    norm_target = f\"{dataroot}/preprocessing_outputs/normalized_data\"\n",
    "    target = norm_target + folder + name + \".png\"\n",
    "    img, _ = PILReader().get_data(PILReader().read(target))\n",
    "    #img = load_image(dataroot + \"/raw\" + filepath)\n",
    "\n",
    "    folder, name, ext = split_filepath(maskpath)\n",
    "    meta_path = f\"{dataroot}/processed\" + folder + name + \".csv\"\n",
    "    df = pd.read_csv(meta_path)\n",
    "    width, height = df['Right'].max(), df['Bottom'].max()\n",
    "    #print(img.shape, width, height, os.path.split(meta_path)[1])\n",
    "    if width == img.shape[0] and height == img.shape[1]:\n",
    "        shapes.add(img.shape)\n",
    "    else:\n",
    "        print(mask_frame(f\"{dataroot}/raw\", maskpath))\n",
    "exts, shapes #file_types[LABELED][\".tiff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([s[2] for s in shapes if len(s) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_obj = data_map[\"Objects\"]\n",
    "print(num_obj[num_obj > 2000])\n",
    "num_obj = num_obj[num_obj < 2000]\n",
    "print(len(num_obj), sum(num_obj), set(num_obj))\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(np.log2([x for x in num_obj]), bins=100)\n",
    "plt.title(\"Number of segmented objects per file\")\n",
    "plt.xlabel(\"Number of objects (log2)\")\n",
    "#plt.xticks([2.0 ** x for x in range(5)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(n for n in (data_map[\"Width\"] * data_map[\"Height\"]))))\n",
    "\n",
    "area = data_map[\"Width\"] * data_map[\"Height\"]\n",
    "print(\"Too big:\", area[area > 10 ** 7].count())\n",
    "#area = area[area < 10 ** 7]\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(np.log2(area), bins=100)\n",
    "#plt.hist([np.log2(n) for n in numbers if n < 2000], bins=100)\n",
    "plt.title(\"Size of of mask files\")\n",
    "plt.xlabel(\"Size of file (log2)\")\n",
    "#plt.xticks([2.0 ** x for x in range(5)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(set(n[2] for n in numbers))\n",
    "\n",
    "density = 1 - (data_map[\"Background\"] / data_map[\"Width\"] / data_map[\"Height\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(density, bins=100)\n",
    "#plt.hist([-np.log2(n[2]) for n in numbers], bins=100)\n",
    "plt.title(\"Density of segmented objects per file\")\n",
    "plt.xlabel(\"Density of objects\")\n",
    "#plt.xticks([2.0 ** x for x in range(5)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = (density / data_map[\"Objects\"] / np.pi) ** .5\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(radius, bins=100)\n",
    "#plt.hist([-np.log2(n[2]) for n in numbers], bins=100)\n",
    "plt.title(\"Average radius of segmented objects per file\")\n",
    "plt.xlabel(\"Radius of objects (in %)\")\n",
    "#plt.xticks([2.0 ** x for x in range(8)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
