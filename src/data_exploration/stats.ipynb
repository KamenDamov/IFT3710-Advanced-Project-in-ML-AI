{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def split_filepath(filepath):\n",
    "    dirpath, filename = os.path.split(filepath)\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    separator = '/' if (not dirpath or dirpath[-1] != '/') else ''\n",
    "    return dirpath + separator, name, ext\n",
    "\n",
    "def unzip_archive(root, filepath):\n",
    "    dirpath, name, ext = split_filepath(filepath)\n",
    "    if os.path.exists(root + dirpath + name):\n",
    "        return False\n",
    "    print(\"Unzipping archive: \", filepath)\n",
    "    with zipfile.ZipFile(root + filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(root + dirpath)\n",
    "    if os.path.exists(root + dirpath + name):\n",
    "        return True\n",
    "    print(\"!WARNING! Archive did not produce folder: \", root + filepath)\n",
    "    return False\n",
    "\n",
    "def enumerate_dataset(root, folder = '/'):\n",
    "    print(\"Enumerating folder: \", folder)\n",
    "    for filename in os.listdir(root + folder):\n",
    "        filepath = folder + filename\n",
    "        dirpath, name, ext = split_filepath(filepath)\n",
    "        yield filepath, dirpath, name, ext\n",
    "\n",
    "        if ext == '.zip':\n",
    "            if unzip_archive(root, filepath):\n",
    "                yield (dirpath + name), dirpath, name, ''\n",
    "            else:\n",
    "                continue\n",
    "        elif ext:\n",
    "            continue\n",
    "\n",
    "        for fullpath, dirpath, name, ext in enumerate_dataset(root, dirpath + name + \"/\"):\n",
    "            yield fullpath, dirpath, name, ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_types = [\".bmp\", \".png\", \".tif\", \".tiff\"]\n",
    "misc_types = [\".md\", \".zip\", \".txt\", \".csv\", \".py\"]\n",
    "\n",
    "files_by_type = {type:set() for type in (img_types + misc_types)}\n",
    "\n",
    "dataroot = \"../../data\"\n",
    "for filepath, dirpath, name, ext in enumerate_dataset(dataroot + \"/raw\", folder= \"/zenodo/\"):\n",
    "    if not ext:\n",
    "        continue\n",
    "    files_by_type[ext].add(filepath)\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "plt.bar(img_types, [len(files_by_type[type]) for type in img_types], label='Files')\n",
    "plt.title(\"File types in dataset\")\n",
    "plt.xlabel(\"File type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LABELED = 'Labeled'\n",
    "MASK = 'Mask'\n",
    "UNLABELED = 'Unlabeled'\n",
    "SYNTHETIC = 'Synthetic'\n",
    "\n",
    "file_types = {cat:{type:set() for type in (img_types + misc_types)} for cat in [LABELED, MASK, UNLABELED, SYNTHETIC]}\n",
    "\n",
    "def mask_map(category):\n",
    "    if category == MASK:\n",
    "        yield (\"/Public/images\", \"/Public/labels\")\n",
    "        yield (\"/Public/WSI\", \"/Public/WSI-labels\")\n",
    "        yield (\"/Training-labeled/images\", \"/Training-labeled/labels\")\n",
    "        yield (\"/Tuning/images\", \"/Tuning/labels\")\n",
    "    if category == SYNTHETIC:\n",
    "        yield (\"/Hidden/images\", \"/Hidden/osilab_seg\")\n",
    "        yield (\"/Public/images\", \"/Public/1st_osilab_seg\")\n",
    "        yield (\"/Public/WSI\", \"/Public/osilab_seg_WSI\")\n",
    "\n",
    "def categorize(dirpath):\n",
    "    for (img, mask) in mask_map(MASK):\n",
    "        if mask in dirpath:\n",
    "            return MASK\n",
    "        elif img in dirpath:\n",
    "            return LABELED\n",
    "    for (img, mask) in mask_map(SYNTHETIC):\n",
    "        if mask in dirpath:\n",
    "            return SYNTHETIC\n",
    "    return UNLABELED\n",
    "\n",
    "for type, paths in files_by_type.items():\n",
    "    for filepath in paths:\n",
    "        file_types[categorize(filepath)][type].add(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in [LABELED, MASK, UNLABELED, SYNTHETIC]:\n",
    "    types = file_types[cat]\n",
    "    counts = {k:len(s) for k, s in types.items()}\n",
    "    print(cat, sum(counts.values()), counts)\n",
    "\n",
    "x = np.arange(len(img_types))  # the label locations\n",
    "width = 0.25\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "\n",
    "index = 0\n",
    "for cat, data in file_types.items():\n",
    "    plt.bar(x + index * width, [len(data[key]) for key in img_types], width, label=cat)\n",
    "    index += 1\n",
    "    \n",
    "plt.title(\"File types in dataset\")\n",
    "plt.xlabel(\"File type\")\n",
    "plt.xticks(x + width, img_types)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_assoc = {}\n",
    "visited = set(file_types[MASK][\".tiff\"])\n",
    "\n",
    "def get_mask_path(img_path):\n",
    "    folder, name, ext = split_filepath(img_path)\n",
    "    if \"WSI\" in folder:\n",
    "        return folder.replace(\"/WSI\", \"/WSI-labels\") + name + \"_label.tiff\"\n",
    "    if \"/images\" in folder:\n",
    "        return folder.replace(\"/images\", \"/labels\") + name + \"_label.tiff\"\n",
    "    return None\n",
    "\n",
    "for ext in img_types:\n",
    "    for path in file_types[LABELED][ext]:\n",
    "        mask_path = get_mask_path(path)\n",
    "        if mask_path and os.path.exists(dataroot + \"/raw\" + mask_path):\n",
    "            mask_assoc[path] = mask_path\n",
    "            visited.remove(mask_path)\n",
    "        else:\n",
    "            print(\"Missing mask: \", dataroot + \"/raw\", mask_path, path)\n",
    "\n",
    "print(len(mask_assoc))\n",
    "print(visited)\n",
    "assert not visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_assoc = {}\n",
    "visited = set(file_types[SYNTHETIC][\".tiff\"])\n",
    "\n",
    "def get_synth_path(img_path):\n",
    "    folder, name, ext = split_filepath(img_path)\n",
    "    if \"/Hidden\" in folder:\n",
    "        return folder.replace(\"/images\", \"/osilab_seg\") + name + \"_label.tiff\"\n",
    "    elif \"/Public/images\" in folder:\n",
    "        return folder.replace(\"/images\", \"/1st_osilab_seg\") + name + \"_label.tiff\"\n",
    "    elif \"/Public/WSI\" in folder:\n",
    "        return folder.replace(\"/WSI\", \"/osilab_seg_WSI\") + name + \"_label.tiff\"\n",
    "    return None\n",
    "\n",
    "for cat in [UNLABELED, LABELED]:\n",
    "    for ext in img_types:\n",
    "        for path in file_types[cat][ext]:\n",
    "            synth_path = get_synth_path(path)\n",
    "            if synth_path and os.path.exists(dataroot + \"/raw\" + synth_path):\n",
    "                synth_assoc[path] = synth_path\n",
    "                visited.remove(synth_path)\n",
    "\n",
    "print(len(synth_assoc))\n",
    "print(visited)\n",
    "assert not visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_frame(root, assoc):\n",
    "    expected = len(assoc)\n",
    "\n",
    "    numbers = []\n",
    "    for img_path, datapath in assoc.items():\n",
    "        print(len(numbers), \"/\", expected)\n",
    "        # Get global statistics\n",
    "        imgT = tif.imread(root + datapath)\n",
    "        numbers.append({\"Path\":img_path, \"Mask\":datapath, \"Width\": imgT.shape[1], \"Height\":imgT.shape[0], \"Objects\": imgT.max(), \"Background\": (imgT == 0).sum()})\n",
    "\n",
    "    return pd.DataFrame(numbers, columns = [\"Path\", \"Mask\", \"Width\", \"Height\", \"Objects\", \"Background\"]).set_index(\"Path\")\n",
    "\n",
    "def save_maskframes(root, assoc, store):\n",
    "    for index, (img_path, mask_path) in enumerate(assoc.items()):\n",
    "        print(index, \"/\", len(assoc))\n",
    "        folder, name, ext = split_filepath(mask_path)\n",
    "        maskframe = mask_frame(root, mask_path)\n",
    "        target = store + folder + name\n",
    "        maskframe.to_csv(target + \".csv\")\n",
    "\n",
    "def merge_lists(compare, merge, listA, listB):\n",
    "    merged = [0] * (len(listA) + len(listB))\n",
    "    indexM, indexA, indexB = 0, 0, 0\n",
    "    while indexA < len(listA) and indexB < len(listB):\n",
    "        cmp = compare(listA[indexA], listB[indexB])\n",
    "        if cmp < 0:\n",
    "            merged[indexM] = listA[indexA]\n",
    "            indexM += 1\n",
    "            indexA += 1\n",
    "        elif cmp > 0:\n",
    "            merged[indexM] = listB[indexB]\n",
    "            indexM += 1\n",
    "            indexB += 1\n",
    "        else:\n",
    "            merged[indexM] = merge(listA[indexA], listB[indexB])\n",
    "            indexM += 1\n",
    "            indexA += 1\n",
    "            indexB += 1\n",
    "            merged.pop()\n",
    "    if indexA < len(listA):\n",
    "        merged[indexM:] = listA[indexA:]\n",
    "    if indexB < len(listB):\n",
    "        merged[indexM:] = listB[indexB:]\n",
    "    return merged\n",
    "\n",
    "def mask_frame_leaf(tensor, bounds):\n",
    "    tensor = tensor[bounds.top:bounds.bottom, bounds.left:bounds.right]\n",
    "    objectIDs = np.unique(tensor)\n",
    "    return [detectObject(tensor, bounds, id) for id in objectIDs]\n",
    "\n",
    "def mask_frame(root, mask_path):\n",
    "    tensor = tif.imread(root + mask_path)\n",
    "    bounds = BoundingBox()\n",
    "    bounds.right = tensor.shape[1]\n",
    "    bounds.bottom = tensor.shape[0]\n",
    "    print(bounds.width(), \"x\", bounds.height())\n",
    "    print(tensor.max(), \"objects\")\n",
    "    objects = mask_frame_branch(tensor, bounds)\n",
    "    for object in objects:\n",
    "        normalizeObject(object)\n",
    "    return pd.DataFrame(objects, columns = [\"ID\", \"X\", \"Y\", \"Left\", \"Right\", \"Top\", \"Bottom\", \"Area\"]).set_index(\"ID\")\n",
    "\n",
    "def mask_frame_branch(tensor, bounds):\n",
    "    if bounds.small():\n",
    "        return mask_frame_leaf(tensor, bounds)\n",
    "    splitA, splitB = bounds.split()\n",
    "    objectsA, objectsB = mask_frame_branch(tensor, splitA), mask_frame_branch(tensor, splitB)\n",
    "    merged = merge_lists(compareObjects, mergeObjects, objectsA, objectsB)\n",
    "    return merged\n",
    "\n",
    "class BoundingBox:\n",
    "    def __init__(self):\n",
    "        self.left = 0\n",
    "        self.right = 0\n",
    "        self.top = 0\n",
    "        self.bottom = 0\n",
    "    \n",
    "    def copy(self):\n",
    "        bounds = BoundingBox()\n",
    "        bounds.left = self.left\n",
    "        bounds.right = self.right\n",
    "        bounds.top = self.top\n",
    "        bounds.bottom = self.bottom\n",
    "        return bounds\n",
    "    \n",
    "    def width(self):\n",
    "        return self.right - self.left\n",
    "    \n",
    "    def height(self):\n",
    "        return self.bottom - self.top\n",
    "    \n",
    "    def small(self):\n",
    "        return self.width() < 128 and self.height() < 128\n",
    "    \n",
    "    def split(self):\n",
    "        boundsA = self.copy()\n",
    "        boundsB = self.copy()\n",
    "        if self.height() < self.width():\n",
    "            #split = self.left + int(np.exp2(np.ceil(np.log2(self.width()) - 1)))\n",
    "            split = self.left + self.width() // 2\n",
    "            boundsA.right = split\n",
    "            boundsB.left = split\n",
    "        else:\n",
    "            #split = self.top + int(np.exp2(np.ceil(np.log2(self.height()) - 1)))\n",
    "            split = self.top + self.height() // 2\n",
    "            boundsA.bottom = split\n",
    "            boundsB.top = split\n",
    "        return (boundsA, boundsB)\n",
    "\n",
    "def normalizeObject(object):\n",
    "    object[\"X\"] = int(np.round(object[\"X\"]))\n",
    "    object[\"Y\"] = int(np.round(object[\"Y\"]))\n",
    "    return object\n",
    "\n",
    "def detectObject(tensor, bounds, id):\n",
    "    # Get local statistics\n",
    "    rows, cols = np.where(tensor == id)\n",
    "    x = bounds.left + cols.mean()\n",
    "    y = bounds.top + rows.mean()\n",
    "    left = bounds.left + cols.min()\n",
    "    right = bounds.left + cols.max() + 1\n",
    "    top = bounds.top + rows.min()\n",
    "    bottom = bounds.top + rows.max() + 1\n",
    "    area = len(rows)\n",
    "    return {\"ID\": id, \"X\": x, \"Y\": y, \"Left\": left, \"Right\": right, \"Top\": top, \"Bottom\": bottom, \"Area\": area}\n",
    "\n",
    "def compareObjects(objectA, objectB):\n",
    "    return objectA[\"ID\"] - objectB[\"ID\"]\n",
    "\n",
    "def mergeObjects(objectA, objectB):\n",
    "    assert objectA[\"ID\"] == objectB[\"ID\"]\n",
    "    area = objectA[\"Area\"] + objectB[\"Area\"]\n",
    "    x = (objectA[\"X\"] * objectA[\"Area\"] + objectB[\"X\"] * objectB[\"Area\"]) / area\n",
    "    y = (objectA[\"Y\"] * objectA[\"Area\"] + objectB[\"Y\"] * objectB[\"Area\"]) / area\n",
    "    left = min(objectA[\"Left\"], objectB[\"Left\"])\n",
    "    right = max(objectA[\"Right\"], objectB[\"Right\"])\n",
    "    top = min(objectA[\"Top\"], objectB[\"Top\"])\n",
    "    bottom = max(objectA[\"Bottom\"], objectB[\"Bottom\"])\n",
    "    return {\"ID\": objectA[\"ID\"], \"X\": x, \"Y\": y, \"Left\":left, \"Right\":right, \"Top\": top, \"Bottom\":bottom, \"Area\": area}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = dataset_frame(dataroot + \"/raw\", mask_assoc)\n",
    "data_map.to_csv(dataroot + \"/zenodo.labels.csv\")\n",
    "\n",
    "synth_map = dataset_frame(dataroot + \"/raw\", synth_assoc)\n",
    "synth_map.to_csv(dataroot + \"/zenodo.synth.csv\")\n",
    "\n",
    "save_maskframes(dataroot + \"/raw\", mask_assoc, dataroot + \"/processed\")\n",
    "save_maskframes(dataroot + \"/raw\", synth_assoc, dataroot + \"/processed\")\n",
    "#df = mask_frame(dataroot + \"/raw\", \"/zenodo/Testing/Public/WSI-labels/Tonsil_label.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save black-white mask\n",
    "def save_bw_mask(root, store, datapath):\n",
    "    imgT = tif.imread(root + datapath)\n",
    "    im = Image.fromarray((imgT != 0).astype('uint8')*255)\n",
    "    folder, name, ext = split_filepath(datapath)\n",
    "    target = store + folder\n",
    "    os.makedirs(target, exist_ok=True)\n",
    "    maskfile = target + name + \".png\"\n",
    "    im.save(maskfile)\n",
    "\n",
    "# TOO SLOW\n",
    "# Save hue-vector mask\n",
    "def save_hue_mask(root, store, datapath):\n",
    "    imgT = tif.imread(root + datapath)\n",
    "    imgTC = np.zeros((imgT.shape[0], imgT.shape[1], 3), dtype=np.float32)\n",
    "    N = imgT.max()\n",
    "    for i in range(1, N+1):\n",
    "        rows, cols = np.where(imgT == i)\n",
    "        bounds = [rows.min(), rows.max(), cols.min(), cols.max()]\n",
    "        middle = np.array([rows.mean(), cols.mean()])\n",
    "        for r, c in zip(rows, cols):\n",
    "            location = np.array([r, c])\n",
    "            vector = (location - middle)/np.array([bounds[1] - bounds[0], bounds[3] - bounds[2]])\n",
    "            # Get euclidian norm\n",
    "            norm = np.linalg.norm(vector)\n",
    "            angle = np.arctan2(vector[1], vector[0])  # Calculate the angle in radians\n",
    "            hue = (angle + np.pi) / (2 * np.pi)  # Normalize angle to [0, 1] for hue\n",
    "            rgb = colorsys.hsv_to_rgb(hue, norm, 1.0)  # Convert HSV to RGB\n",
    "            imgTC[r, c] = rgb\n",
    "    print(imgTC.min(), imgTC.max())\n",
    "    im = Image.fromarray((imgTC * 255).astype('uint8'), mode=\"RGB\")\n",
    "    folder, name, ext = split_filepath(datapath)\n",
    "    target = store + folder\n",
    "    os.makedirs(target, exist_ok=True)\n",
    "    maskfile = target + name + \".vect.png\"\n",
    "    im.save(maskfile)\n",
    "\n",
    "# Save vector mask (tiff)\n",
    "def save_vector_mask(root, framename, datapath):\n",
    "    imgT = tif.imread(root + datapath)\n",
    "    imgTC = np.zeros((imgT.shape[0], imgT.shape[1], 3), dtype=np.float32)\n",
    "    N = imgT.max()\n",
    "    for i in range(1, N+1):\n",
    "        rows, cols = np.where(imgT == i)\n",
    "        bounds = [rows.min(), rows.max(), cols.min(), cols.max()]\n",
    "        middle = np.array([rows.mean(), cols.mean()])\n",
    "        for r, c in zip(rows, cols):\n",
    "            location = np.array([r, c])\n",
    "            vector = (location - middle)/np.array([bounds[1] - bounds[0], bounds[3] - bounds[2]])\n",
    "            # Get euclidian norm\n",
    "            norm = np.linalg.norm(vector)\n",
    "            angle = np.arctan2(vector[1], vector[0])  # Calculate the angle in radians\n",
    "            hue = (angle + np.pi) / (2 * np.pi)  # Normalize angle to [0, 1] for hue\n",
    "            rgb = colorsys.hsv_to_rgb(hue, norm, 1.0)  # Convert HSV to RGB\n",
    "            imgTC[r, c] = rgb\n",
    "    print(imgTC.min(), imgTC.max())\n",
    "    im = Image.fromarray((imgTC * 255).astype('uint8'), mode=\"RGB\")\n",
    "    folder, name, ext = split_filepath(datapath)\n",
    "    target = root + framename + folder\n",
    "    maskfile = target + name + \".vect.png\"\n",
    "    im.save(maskfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_datasets(dataroot):\n",
    "    for filename in os.listdir(dataroot):\n",
    "        dirpath, name, ext = split_filepath(filename)\n",
    "        if ext == \".csv\":\n",
    "            yield pd.read_csv(dataroot + dirpath + filename)\n",
    "\n",
    "def preprocess_masks(dataroot, color = False):\n",
    "    rawroot = dataroot + \"/raw\"\n",
    "    procroot = dataroot + \"/processed\"\n",
    "    for df in enumerate_datasets(dataroot):\n",
    "        for index, datapath in enumerate(df[\"Mask\"]):\n",
    "            print(index, \"/\", len(df))\n",
    "            if color:\n",
    "                save_hue_mask(rawroot, procroot, datapath)\n",
    "            else:\n",
    "                save_bw_mask(rawroot, procroot, datapath)\n",
    "\n",
    "preprocess_masks(dataroot)\n",
    "#save_hue_mask(dataroot + \"/raw\", dataroot + \"/processed\", \"/zenodo/Testing/Public/labels/OpenTest_041_label.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_map[\"Objects\"] < 2000\n",
    "data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valeurs aberrantes?\")\n",
    "data_map[data_map[\"Objects\"] > 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_obj = data_map[\"Objects\"]\n",
    "print(num_obj[num_obj > 2000])\n",
    "num_obj = num_obj[num_obj < 2000]\n",
    "print(len(num_obj), sum(num_obj), set(num_obj))\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(np.log2([x for x in num_obj]), bins=100)\n",
    "plt.title(\"Number of segmented objects per file\")\n",
    "plt.xlabel(\"Number of objects (log2)\")\n",
    "#plt.xticks([2.0 ** x for x in range(5)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(n for n in (data_map[\"Width\"] * data_map[\"Height\"]))))\n",
    "\n",
    "area = data_map[\"Width\"] * data_map[\"Height\"]\n",
    "print(\"Too big:\", area[area > 10 ** 7].count())\n",
    "#area = area[area < 10 ** 7]\n",
    "\n",
    "# Display parallel histograms\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(np.log2(area), bins=100)\n",
    "#plt.hist([np.log2(n) for n in numbers if n < 2000], bins=100)\n",
    "plt.title(\"Size of of mask files\")\n",
    "plt.xlabel(\"Size of file (log2)\")\n",
    "#plt.xticks([2.0 ** x for x in range(5)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(set(n[2] for n in numbers))\n",
    "\n",
    "density = 1 - (data_map[\"Background\"] / data_map[\"Width\"] / data_map[\"Height\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(density, bins=100)\n",
    "#plt.hist([-np.log2(n[2]) for n in numbers], bins=100)\n",
    "plt.title(\"Density of segmented objects per file\")\n",
    "plt.xlabel(\"Density of objects\")\n",
    "#plt.xticks([2.0 ** x for x in range(5)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = (density / data_map[\"Objects\"] / np.pi) ** .5\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(radius, bins=100)\n",
    "#plt.hist([-np.log2(n[2]) for n in numbers], bins=100)\n",
    "plt.title(\"Average radius of segmented objects per file\")\n",
    "plt.xlabel(\"Radius of objects (in %)\")\n",
    "#plt.xticks([2.0 ** x for x in range(8)])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
