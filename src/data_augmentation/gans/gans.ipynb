{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\models\\\\unet\\\\custom_unet.py\")))\n",
    "sys.path.append(project_root)\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cycle_gan.models.pix2pix_model import Pix2PixModel\n",
    "from cycle_gan.options.base_options import BaseOptions\n",
    "from cycle_gan.data.produce_dataset import Pix2PixDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "from cycle_gan.util.visualizer import Visualizer\n",
    "import time\n",
    "from gans import Training, Options\n",
    "from metrics import compute_metric\n",
    "from infer import Infer\n",
    "import matplotlib.pyplot as plt\n",
    "from models.unet.custom_unet import UNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cGAN: Gen(mask | image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\images\"\n",
    "label_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\labels\"\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = Pix2PixDataset(image_dir, label_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Loaded dataset with {len(dataset)} image-mask pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\transformed_images_labels\\\\images\"   # Raw cell images\n",
    "mask_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\preprocessing_outputs\\\\transformed_images_labels\\\\labels\"     # Corresponding segmentation masks\n",
    "input_tuning_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\images\"\n",
    "output_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Training-unlabeled\\\\Training-unlabeled\\\\labels\" # Output paired images\n",
    "unlabeled_images_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\transformed_images_labels\\\\images\"  # Unlabeled images\n",
    "pseudo_mask_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\dataset_pix2pix\\\\test\\\\generated_masks\"  # Where to save masks\n",
    "pseudo_mask_output_tuning_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "options = Options()\n",
    "training = Training()\n",
    "infer = Infer()\n",
    "\n",
    "opt = options.get_opt()\n",
    "pix2pix_model = training.load_pix2pix_model(opt)\n",
    "\n",
    "# Train pix2pix \n",
    "training.train_model(pix2pix_model, dataset, opt)\n",
    "\n",
    "pix2pix_model = Pix2PixModel(opt)\n",
    "checkpoint_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\models\\\\pix_2_pix_bigger_corpus\\\\latest_generator.pth\"\n",
    "\n",
    "# Load state dictionary\n",
    "#pix2pix_model.load_networks(\"latest\")\n",
    "pix2pix_model.netG.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "pix2pix_model.netG.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Generate pseudo-masks\n",
    "#infer.generate_pseudo_masks(pix2pix_model, input_tuning_dir, pseudo_mask_output_tuning_path)\n",
    "#print(\"Synthetic pseudo-masks added to training dataset!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_2\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test U-Net with base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer on test set\n",
    "infer = Infer()\n",
    "unet = UNet(in_channels=3, out_channels=3, bilinear=True)\n",
    "unet.load_state_dict(torch.load(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\unet_cell_segmentation_base_data.pth\"))\n",
    "unet.eval()\n",
    "\n",
    "input_tuning_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\images\"\n",
    "path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\inference_base_data\"\n",
    "infer.generate_pseudo_masks(unet, input_tuning_dir, path, image_gen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "#pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output_unet_base\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test U-Net with augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = Infer()\n",
    "unet = UNet(in_channels=3, out_channels=3, bilinear=True)\n",
    "unet.load_state_dict(torch.load(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\unet_cell_segmentation_augmented_datas.pth\"))\n",
    "unet.eval()\n",
    "input_tuning_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\images\"\n",
    "path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\inference_augmented_data\"\n",
    "\n",
    "infer.generate_pseudo_masks(unet, input_tuning_dir, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "#pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output_unet_augmented\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo-masks\n",
    "input_unlabelde_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Testing-20250120T224249Z-002\\\\Testing\\\\Hidden\\\\images\"\n",
    "pseudo_mask_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\test\\\\generated_masks\"  # Where to save masks\n",
    "infer.generate_pseudo_masks(pix2pix_model, input_unlabelde_dir, pseudo_mask_output_path)\n",
    "print(\"Synthetic pseudo-masks added to training dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on tuning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tuning_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Tuning\\\\images\"\n",
    "pseudo_mask_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_4\"  # Where to save masks\n",
    "infer.generate_pseudo_masks(pix2pix_model, input_tuning_dir, pseudo_mask_output_path)\n",
    "print(\"Synthetic pseudo-masks added to training dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Tuning\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_4\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \"_label.tiff\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output_tuning\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new samples\n",
    "# cGAN: Gen(image | mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset\n",
    "image_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\labels\"\n",
    "label_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\images\"\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = Pix2PixDataset(image_dir, label_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Loaded dataset with {len(dataset)} image-mask pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "training = Training()\n",
    "infer = Infer()\n",
    "\n",
    "opt = options.get_opt()\n",
    "pix2pix_model = training.load_pix2pix_model(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train pix2pix\n",
    "training.train_model(pix2pix_model, dataset, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pix_model = Pix2PixModel(opt)\n",
    "checkpoint_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\gans\\\\latest_generator.pth\"\n",
    "\n",
    "pix2pix_model.netG.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "pix2pix_model.netG.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Generate pseudo-masks\n",
    "input_tuning_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\gans\\\\base_gan\\\\generated_samples\"\n",
    "pseudo_images_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\new_samples\\\\generated_images\"  # Where to save masks\n",
    "infer.generate_pseudo_masks(pix2pix_model, input_tuning_dir, pseudo_images_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
