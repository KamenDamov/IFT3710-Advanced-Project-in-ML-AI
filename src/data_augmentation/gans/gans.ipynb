{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\cupy\\_environment.py:217: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\models\\\\unet\\\\custom_unet.py\")))\n",
    "sys.path.append(project_root)\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cycle_gan.models.pix2pix_model import Pix2PixModel\n",
    "from cycle_gan.options.base_options import BaseOptions\n",
    "from cycle_gan.data.produce_dataset import Pix2PixDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "from cycle_gan.util.visualizer import Visualizer\n",
    "import time\n",
    "from gans import Training, Options\n",
    "from metrics import compute_metric\n",
    "from infer import Infer\n",
    "import matplotlib.pyplot as plt\n",
    "from models.unet.custom_unet import UNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cGAN: Gen(mask | image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 2210 image-mask pairs.\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\images\"\n",
    "label_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\labels\"\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = Pix2PixDataset(image_dir, label_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Loaded dataset with {len(dataset)} image-mask pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Dropout(p=0.5, inplace=False)\n",
      "          (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 11.372 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.766 M\n",
      "-----------------------------------------------\n",
      "The number of training images = 2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 445, in request\n",
      "    self.endheaders()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 1298, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 1058, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 996, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 276, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000027DE8C374D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027DE8C374D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\visdom\\__init__.py\", line 756, in _send\n",
      "    return self._handle_post(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\visdom\\__init__.py\", line 720, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py\", line 700, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027DE8C374D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "[WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
      "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: C:\\Users\\kamen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m visdom.server -p 8000 &>/dev/null &\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkamendamov123\u001b[0m (\u001b[33mkamendamov123-universit-de-montr-al\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\src\\data_augmentation\\gans\\wandb\\run-20250320_205645-kmwsn80r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kamendamov123-universit-de-montr-al/CycleGAN-and-pix2pix/runs/kmwsn80r' target=\"_blank\">cell_segmentation_pix2pix</a></strong> to <a href='https://wandb.ai/kamendamov123-universit-de-montr-al/CycleGAN-and-pix2pix' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kamendamov123-universit-de-montr-al/CycleGAN-and-pix2pix' target=\"_blank\">https://wandb.ai/kamendamov123-universit-de-montr-al/CycleGAN-and-pix2pix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kamendamov123-universit-de-montr-al/CycleGAN-and-pix2pix/runs/kmwsn80r' target=\"_blank\">https://wandb.ai/kamendamov123-universit-de-montr-al/CycleGAN-and-pix2pix/runs/kmwsn80r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 1, iters: 200, time: 0.025, data: 0.052) G_GAN: 49.874 G_L1: 55.370 D_real: 42.148 D_fake: 54.676 \n",
      "(epoch: 1, iters: 400, time: 0.028, data: 0.008) G_GAN: 26.288 G_L1: 19.872 D_real: 21.001 D_fake: 30.602 \n",
      "(epoch: 1, iters: 600, time: 0.026, data: 0.006) G_GAN: 34.989 G_L1: 24.062 D_real: 39.227 D_fake: 39.293 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m pix2pix_model \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mload_pix2pix_model(opt)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train pix2pix \u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpix2pix_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m pix2pix_model \u001b[38;5;241m=\u001b[39m Pix2PixModel(opt)\n\u001b[0;32m     20\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mkamen\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDev\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mH25\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mIFT3710\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mIFT3710-Advanced-Project-in-ML-AI\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata_augmentation\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpix_2_pix_bigger_corpus\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlatest_generator.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\src\\data_augmentation\\gans\\gans.py:109\u001b[0m, in \u001b[0;36mTraining.train_model\u001b[1;34m(self, model, dataset, opt)\u001b[0m\n\u001b[0;32m    107\u001b[0m total_iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    108\u001b[0m epoch_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m--> 109\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# unpack data from dataset and apply preprocessing\u001b[39;00m\n\u001b[0;32m    110\u001b[0m model\u001b[38;5;241m.\u001b[39moptimize_parameters()   \u001b[38;5;66;03m# calculate loss functions, get gradients, update network weights\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Update the loss plots\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\src\\data_augmentation\\gans\\cycle_gan\\models\\pix2pix_model.py:82\u001b[0m, in \u001b[0;36mPix2PixModel.set_input\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03mThe option 'direction' can be used to swap images in domain A and domain B.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     81\u001b[0m AtoB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAtoB\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreal_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mAtoB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreal_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m AtoB \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m AtoB \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\transformed_images_labels\\\\images\"   # Raw cell images\n",
    "mask_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\preprocessing_outputs\\\\transformed_images_labels\\\\labels\"     # Corresponding segmentation masks\n",
    "input_tuning_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\images\"\n",
    "output_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Training-unlabeled\\\\Training-unlabeled\\\\labels\" # Output paired images\n",
    "unlabeled_images_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\transformed_images_labels\\\\images\"  # Unlabeled images\n",
    "pseudo_mask_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\dataset_pix2pix\\\\test\\\\generated_masks\"  # Where to save masks\n",
    "pseudo_mask_output_tuning_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "options = Options()\n",
    "training = Training()\n",
    "infer = Infer()\n",
    "\n",
    "opt = options.get_opt()\n",
    "pix2pix_model = training.load_pix2pix_model(opt)\n",
    "\n",
    "# Train pix2pix \n",
    "training.train_model(pix2pix_model, dataset, opt)\n",
    "\n",
    "pix2pix_model = Pix2PixModel(opt)\n",
    "checkpoint_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\models\\\\pix_2_pix_bigger_corpus\\\\latest_generator.pth\"\n",
    "\n",
    "# Load state dictionary\n",
    "#pix2pix_model.load_networks(\"latest\")\n",
    "pix2pix_model.netG.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "pix2pix_model.netG.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Generate pseudo-masks\n",
    "#infer.generate_pseudo_masks(pix2pix_model, input_tuning_dir, pseudo_mask_output_tuning_path)\n",
    "#print(\"Synthetic pseudo-masks added to training dataset!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_2\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test U-Net with base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamen\\AppData\\Local\\Temp\\ipykernel_23236\\4294753844.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet.load_state_dict(torch.load(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\unet_cell_segmentation_base_data.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell_00001.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00001.png\n",
      "Processing cell_00002.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00002.png\n",
      "Processing cell_00003.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00003.png\n",
      "Processing cell_00004.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00004.png\n",
      "Processing cell_00005.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00005.png\n",
      "Processing cell_00006.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00006.png\n",
      "Processing cell_00007.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00007.png\n",
      "Processing cell_00008.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00008.png\n",
      "Processing cell_00009.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00009.png\n",
      "Processing cell_00010.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00010.png\n",
      "Processing cell_00011.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00011.png\n",
      "Processing cell_00012.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00012.png\n",
      "Processing cell_00013.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00013.png\n",
      "Processing cell_00014.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00014.png\n",
      "Processing cell_00015.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00015.png\n",
      "Processing cell_00016.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00016.png\n",
      "Processing cell_00017.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00017.png\n",
      "Processing cell_00018.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00018.png\n",
      "Processing cell_00019.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00019.png\n",
      "Processing cell_00020.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00020.png\n",
      "Processing cell_00021.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00021.png\n",
      "Processing cell_00022.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00022.png\n",
      "Processing cell_00023.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00023.png\n",
      "Processing cell_00024.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00024.png\n",
      "Processing cell_00025.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00025.png\n",
      "Processing cell_00026.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00026.png\n",
      "Processing cell_00027.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00027.png\n",
      "Processing cell_00028.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00028.png\n",
      "Processing cell_00029.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00029.png\n",
      "Processing cell_00030.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00030.png\n",
      "Processing cell_00031.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00031.png\n",
      "Processing cell_00032.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00032.png\n",
      "Processing cell_00033.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00033.png\n",
      "Processing cell_00034.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00034.png\n",
      "Processing cell_00035.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00035.png\n",
      "Processing cell_00036.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00036.png\n",
      "Processing cell_00037.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00037.png\n",
      "Processing cell_00038.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00038.png\n",
      "Processing cell_00039.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00039.png\n",
      "Processing cell_00040.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00040.png\n",
      "Processing cell_00041.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00041.png\n",
      "Processing cell_00042.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00042.png\n",
      "Processing cell_00043.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00043.png\n",
      "Processing cell_00044.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00044.png\n",
      "Processing cell_00045.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00045.png\n",
      "Processing cell_00046.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00046.png\n",
      "Processing cell_00047.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00047.png\n",
      "Processing cell_00048.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00048.png\n",
      "Processing cell_00049.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00049.png\n",
      "Processing cell_00050.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00050.png\n",
      "Processing cell_00051.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00051.png\n",
      "Processing cell_00052.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00052.png\n",
      "Processing cell_00053.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00053.png\n",
      "Processing cell_00054.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00054.png\n",
      "Processing cell_00055.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00055.png\n",
      "Processing cell_00056.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00056.png\n",
      "Processing cell_00057.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00057.png\n",
      "Processing cell_00058.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00058.png\n",
      "Processing cell_00059.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00059.png\n",
      "Processing cell_00060.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00060.png\n",
      "Processing cell_00061.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00061.png\n",
      "Processing cell_00062.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00062.png\n",
      "Processing cell_00063.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00063.png\n",
      "Processing cell_00064.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00064.png\n",
      "Processing cell_00065.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00065.png\n",
      "Processing cell_00066.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00066.png\n",
      "Processing cell_00067.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00067.png\n",
      "Processing cell_00068.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00068.png\n",
      "Processing cell_00069.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00069.png\n",
      "Processing cell_00070.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00070.png\n",
      "Processing cell_00071.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00071.png\n",
      "Processing cell_00072.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00072.png\n",
      "Processing cell_00073.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00073.png\n",
      "Processing cell_00074.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00074.png\n",
      "Processing cell_00075.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00075.png\n",
      "Processing cell_00076.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00076.png\n",
      "Processing cell_00077.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00077.png\n",
      "Processing cell_00078.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00078.png\n",
      "Processing cell_00079.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00079.png\n",
      "Processing cell_00080.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00080.png\n",
      "Processing cell_00081.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00081.png\n",
      "Processing cell_00082.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00082.png\n",
      "Processing cell_00083.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00083.png\n",
      "Processing cell_00084.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00084.png\n",
      "Processing cell_00085.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00085.png\n",
      "Processing cell_00086.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00086.png\n",
      "Processing cell_00087.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00087.png\n",
      "Processing cell_00088.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00088.png\n",
      "Processing cell_00089.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00089.png\n",
      "Processing cell_00090.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00090.png\n",
      "Processing cell_00091.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00091.png\n",
      "Processing cell_00092.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00092.png\n",
      "Processing cell_00093.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00093.png\n",
      "Processing cell_00094.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00094.png\n",
      "Processing cell_00095.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00095.png\n",
      "Processing cell_00096.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00096.png\n",
      "Processing cell_00097.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00097.png\n",
      "Processing cell_00098.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00098.png\n",
      "Processing cell_00099.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00099.png\n",
      "Processing cell_00100.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00100.png\n",
      "Processing cell_00101.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_base_data\\cell_00101.png\n"
     ]
    }
   ],
   "source": [
    "# Infer on test set\n",
    "infer = Infer()\n",
    "unet = UNet(in_channels=3, out_channels=3, bilinear=True)\n",
    "unet.load_state_dict(torch.load(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\unet_cell_segmentation_base_data.pth\"))\n",
    "unet.eval()\n",
    "\n",
    "input_tuning_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\images\"\n",
    "path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\inference_base_data\"\n",
    "infer.generate_pseudo_masks(unet, input_tuning_dir, path, image_gen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "#pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output_unet_base\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test U-Net with augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamen\\AppData\\Local\\Temp\\ipykernel_23236\\1961888505.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet.load_state_dict(torch.load(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\unet_cell_segmentation_augmented_datas.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell_00001.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00001.png\n",
      "Processing cell_00002.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00002.png\n",
      "Processing cell_00003.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00003.png\n",
      "Processing cell_00004.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00004.png\n",
      "Processing cell_00005.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00005.png\n",
      "Processing cell_00006.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00006.png\n",
      "Processing cell_00007.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00007.png\n",
      "Processing cell_00008.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00008.png\n",
      "Processing cell_00009.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00009.png\n",
      "Processing cell_00010.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00010.png\n",
      "Processing cell_00011.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00011.png\n",
      "Processing cell_00012.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00012.png\n",
      "Processing cell_00013.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00013.png\n",
      "Processing cell_00014.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00014.png\n",
      "Processing cell_00015.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00015.png\n",
      "Processing cell_00016.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00016.png\n",
      "Processing cell_00017.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00017.png\n",
      "Processing cell_00018.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00018.png\n",
      "Processing cell_00019.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00019.png\n",
      "Processing cell_00020.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00020.png\n",
      "Processing cell_00021.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00021.png\n",
      "Processing cell_00022.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00022.png\n",
      "Processing cell_00023.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00023.png\n",
      "Processing cell_00024.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00024.png\n",
      "Processing cell_00025.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00025.png\n",
      "Processing cell_00026.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00026.png\n",
      "Processing cell_00027.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00027.png\n",
      "Processing cell_00028.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00028.png\n",
      "Processing cell_00029.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00029.png\n",
      "Processing cell_00030.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00030.png\n",
      "Processing cell_00031.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00031.png\n",
      "Processing cell_00032.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00032.png\n",
      "Processing cell_00033.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00033.png\n",
      "Processing cell_00034.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00034.png\n",
      "Processing cell_00035.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00035.png\n",
      "Processing cell_00036.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00036.png\n",
      "Processing cell_00037.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00037.png\n",
      "Processing cell_00038.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00038.png\n",
      "Processing cell_00039.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00039.png\n",
      "Processing cell_00040.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00040.png\n",
      "Processing cell_00041.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00041.png\n",
      "Processing cell_00042.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00042.png\n",
      "Processing cell_00043.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00043.png\n",
      "Processing cell_00044.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00044.png\n",
      "Processing cell_00045.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00045.png\n",
      "Processing cell_00046.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00046.png\n",
      "Processing cell_00047.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00047.png\n",
      "Processing cell_00048.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00048.png\n",
      "Processing cell_00049.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00049.png\n",
      "Processing cell_00050.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00050.png\n",
      "Processing cell_00051.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00051.png\n",
      "Processing cell_00052.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00052.png\n",
      "Processing cell_00053.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00053.png\n",
      "Processing cell_00054.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00054.png\n",
      "Processing cell_00055.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00055.png\n",
      "Processing cell_00056.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00056.png\n",
      "Processing cell_00057.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00057.png\n",
      "Processing cell_00058.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00058.png\n",
      "Processing cell_00059.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00059.png\n",
      "Processing cell_00060.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00060.png\n",
      "Processing cell_00061.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00061.png\n",
      "Processing cell_00062.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00062.png\n",
      "Processing cell_00063.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00063.png\n",
      "Processing cell_00064.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00064.png\n",
      "Processing cell_00065.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00065.png\n",
      "Processing cell_00066.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00066.png\n",
      "Processing cell_00067.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00067.png\n",
      "Processing cell_00068.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00068.png\n",
      "Processing cell_00069.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00069.png\n",
      "Processing cell_00070.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00070.png\n",
      "Processing cell_00071.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00071.png\n",
      "Processing cell_00072.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00072.png\n",
      "Processing cell_00073.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00073.png\n",
      "Processing cell_00074.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00074.png\n",
      "Processing cell_00075.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00075.png\n",
      "Processing cell_00076.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00076.png\n",
      "Processing cell_00077.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00077.png\n",
      "Processing cell_00078.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00078.png\n",
      "Processing cell_00079.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00079.png\n",
      "Processing cell_00080.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00080.png\n",
      "Processing cell_00081.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00081.png\n",
      "Processing cell_00082.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00082.png\n",
      "Processing cell_00083.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00083.png\n",
      "Processing cell_00084.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00084.png\n",
      "Processing cell_00085.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00085.png\n",
      "Processing cell_00086.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00086.png\n",
      "Processing cell_00087.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00087.png\n",
      "Processing cell_00088.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00088.png\n",
      "Processing cell_00089.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00089.png\n",
      "Processing cell_00090.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00090.png\n",
      "Processing cell_00091.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00091.png\n",
      "Processing cell_00092.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00092.png\n",
      "Processing cell_00093.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00093.png\n",
      "Processing cell_00094.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00094.png\n",
      "Processing cell_00095.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00095.png\n",
      "Processing cell_00096.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00096.png\n",
      "Processing cell_00097.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00097.png\n",
      "Processing cell_00098.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00098.png\n",
      "Processing cell_00099.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00099.png\n",
      "Processing cell_00100.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00100.png\n",
      "Processing cell_00101.png\n",
      "Generated pseudo-mask saved: c:\\Users\\kamen\\Dev\\School\\H25\\IFT3710\\IFT3710-Advanced-Project-in-ML-AI\\data\\dataset_pix2pix\\tuning\\inference_augmented_data\\cell_00101.png\n"
     ]
    }
   ],
   "source": [
    "infer = Infer()\n",
    "unet = UNet(in_channels=3, out_channels=3, bilinear=True)\n",
    "unet.load_state_dict(torch.load(\"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\unet_cell_segmentation_augmented_datas.pth\"))\n",
    "unet.eval()\n",
    "input_tuning_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\images\"\n",
    "path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\inference_augmented_data\"\n",
    "\n",
    "infer.generate_pseudo_masks(unet, input_tuning_dir, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\tuning\\\\transformed_images_labels\\\\labels\"\n",
    "#pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_3\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \".png\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output_unet_augmented\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo-masks\n",
    "input_unlabelde_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Testing-20250120T224249Z-002\\\\Testing\\\\Hidden\\\\images\"\n",
    "pseudo_mask_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\test\\\\generated_masks\"  # Where to save masks\n",
    "infer.generate_pseudo_masks(pix2pix_model, input_unlabelde_dir, pseudo_mask_output_path)\n",
    "print(\"Synthetic pseudo-masks added to training dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on tuning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tuning_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Tuning\\\\images\"\n",
    "pseudo_mask_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_4\"  # Where to save masks\n",
    "infer.generate_pseudo_masks(pix2pix_model, input_tuning_dir, pseudo_mask_output_path)\n",
    "print(\"Synthetic pseudo-masks added to training dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\Tuning\\\\labels\"\n",
    "pred_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\tuning\\\\generated_masks_4\"\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    \"compute_metric.py\",  # Script name (can be anything)\n",
    "    \"-g\", gt_path,  # Replace with the actual ground truth path\n",
    "    \"-s\", pred_path,  # Replace with the actual segmentation results path\n",
    "    \"--gt_suffix\", \"_label.tiff\",\n",
    "    \"--seg_suffix\", \".png\",\n",
    "    \"-thre\", \"0.5\", \"0.6\",  # Example thresholds\n",
    "    \"-o\", \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\output_tuning\",  # Output path\n",
    "    \"-n\", \"results\"  # Output file name\n",
    "]\n",
    "\n",
    "# Call the main function\n",
    "compute_metric.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new samples\n",
    "# cGAN: Gen(image | mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset\n",
    "image_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\labels\"\n",
    "label_dir = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\images\"\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = Pix2PixDataset(image_dir, label_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Loaded dataset with {len(dataset)} image-mask pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "training = Training()\n",
    "infer = Infer()\n",
    "\n",
    "opt = options.get_opt()\n",
    "pix2pix_model = training.load_pix2pix_model(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train pix2pix\n",
    "training.train_model(pix2pix_model, dataset, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pix_model = Pix2PixModel(opt)\n",
    "checkpoint_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\gans\\\\latest_generator.pth\"\n",
    "\n",
    "pix2pix_model.netG.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "pix2pix_model.netG.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Generate pseudo-masks\n",
    "input_tuning_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\gans\\\\base_gan\\\\generated_samples\"\n",
    "pseudo_images_output_path = \"c:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\new_samples\\\\generated_images\"  # Where to save masks\n",
    "infer.generate_pseudo_masks(pix2pix_model, input_tuning_dir, pseudo_images_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
