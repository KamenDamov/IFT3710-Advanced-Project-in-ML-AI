{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgan import * \n",
    "import wandb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for your data\n",
    "image_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\images\"\n",
    "mask_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\labels\"\n",
    "\n",
    "# Output directories\n",
    "sample_dir = \"big_unet\"\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "output_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\dataset_pix2pix\\\\new_samples_big_unet\"\n",
    "\n",
    "# Test mask for progress visualization during training\n",
    "test_mask_path = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\gans\\\\base_gan\\\\generated_samples\\\\sample_1_epoch_86.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch training to train a cGAN that takes masks on input, and generates images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 8      # This is fine for most GPUs\n",
    "epochs = 1        # Increase this since your model is still improving\n",
    "lr = 0.0001         # This lower learning rate is good\n",
    "beta1 = 0.5         # Standard for GANs\n",
    "beta2 = 0.999       # Standard value\n",
    "lambda_L1 = 150 \n",
    "\n",
    "# Initialize wandb before any training happens\n",
    "wandb.login()  # You'll need to enter your API key on first run\n",
    "wandb.init(\n",
    "    project=\"cell-gan\",  # Choose an appropriate project name\n",
    "    name=f\"gan-training-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"architecture\": \"big_unet\",\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"beta1\": beta1,\n",
    "        \"beta2\": beta2,\n",
    "        \"lambda_L1\": lambda_L1,\n",
    "        \"input_nc\": 1,\n",
    "        \"output_nc\": 3,\n",
    "        \"ngf\": 256,\n",
    "        \"use_dropout\": True,\n",
    "        \"n_blocks\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "# The rest of your code stays the same until the train_gan function\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data transformations\n",
    "# For images: scale to [-1, 1]\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# For masks: grayscale and scale to [-1, 1]\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = CellGANDataset(\n",
    "    image_dir, mask_dir, \n",
    "    transform=image_transform, \n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize ResNet generator\n",
    "generator = get_generator(\n",
    "    arch_type='small_unet',\n",
    "    input_nc=1,          # mask channels\n",
    "    output_nc=3,         # cell image\n",
    "    ngf=256,             \n",
    "    norm_layer=nn.InstanceNorm2d, \n",
    "    use_dropout=True,\n",
    "    n_blocks=9           # Increase number of ResNet blocks for more parameters\n",
    ")\n",
    "\n",
    "# Initialize PatchGAN discriminator\n",
    "discriminator = PatchGANDiscriminator(\n",
    "    input_nc=4,          # 1 for mask + 3 for image\n",
    "    ndf=64,\n",
    "    n_layers=3,\n",
    "    norm_layer=nn.BatchNorm2d\n",
    ")\n",
    "\n",
    "# Print model sizes\n",
    "print(f\"Generator Architecture: Big Unet\")\n",
    "print(f\"Generator Parameters: {count_parameters(generator):,}\")\n",
    "print(f\"Discriminator Parameters: {count_parameters(discriminator):,}\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Train models\n",
    "trained_generator, trained_discriminator, history = train_gan(\n",
    "    generator, discriminator, train_loader, val_loader, device,\n",
    "    epochs=epochs, lr=lr, beta1=beta1, beta2=beta2, lambda_L1=lambda_L1,\n",
    "    sample_dir=sample_dir, checkpoint_dir=checkpoint_dir,\n",
    "    test_mask_path=test_mask_path\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)\n",
    "\n",
    "# Test inference on masks in a directory and save generated images\n",
    "test_mask_dir = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\src\\\\data_augmentation\\\\gans\\\\base_gan\\\\generated_samples\"\n",
    "\n",
    "# Process each mask and save the generated image\n",
    "process_mask_directory(\n",
    "    trained_generator, \n",
    "    test_mask_dir, \n",
    "    output_dir, \n",
    "    device, \n",
    "    make_comparison=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
