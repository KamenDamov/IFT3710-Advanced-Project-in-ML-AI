{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GAN for novel sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (net): Sequential(\n",
      "    (0): ConvTranspose2d(256, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (19): Tanh()\n",
      "  )\n",
      ")\n",
      "The generator has 4,892,896 trainable parameters\n",
      "Discriminator(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (14): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (17): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (18): Sigmoid()\n",
      "  )\n",
      ")\n",
      "The discriminator has 2,803,904 trainable parameters\n",
      "Epoch [1/1] Batch 0/2210 D Loss: 1.3207 G Loss: 10.6865\n",
      "Epoch [1/1] Batch 50/2210 D Loss: 0.0017 G Loss: 8.2439\n",
      "Epoch [1/1] Batch 100/2210 D Loss: 0.1754 G Loss: 13.6259\n",
      "Epoch [1/1] Batch 150/2210 D Loss: 1.0932 G Loss: 7.5708\n",
      "Epoch [1/1] Batch 200/2210 D Loss: 0.0237 G Loss: 11.3460\n",
      "Epoch [1/1] Batch 250/2210 D Loss: 0.1007 G Loss: 7.4495\n",
      "Epoch [1/1] Batch 300/2210 D Loss: 3.6278 G Loss: 10.5024\n",
      "Epoch [1/1] Batch 350/2210 D Loss: 0.2158 G Loss: 5.3936\n",
      "Epoch [1/1] Batch 400/2210 D Loss: 0.0439 G Loss: 3.6605\n",
      "Epoch [1/1] Batch 450/2210 D Loss: 0.1420 G Loss: 3.9401\n",
      "Epoch [1/1] Batch 500/2210 D Loss: 0.8263 G Loss: 6.1683\n",
      "Epoch [1/1] Batch 550/2210 D Loss: 0.2046 G Loss: 4.1159\n",
      "Epoch [1/1] Batch 600/2210 D Loss: 0.0562 G Loss: 4.0228\n",
      "Epoch [1/1] Batch 650/2210 D Loss: 0.0133 G Loss: 5.1223\n",
      "Epoch [1/1] Batch 700/2210 D Loss: 0.0735 G Loss: 5.3026\n",
      "Epoch [1/1] Batch 750/2210 D Loss: 0.1676 G Loss: 5.3118\n",
      "Epoch [1/1] Batch 800/2210 D Loss: 0.1752 G Loss: 4.9806\n",
      "Epoch [1/1] Batch 850/2210 D Loss: 0.2626 G Loss: 6.6148\n",
      "Epoch [1/1] Batch 900/2210 D Loss: 1.5570 G Loss: 2.3244\n",
      "Epoch [1/1] Batch 950/2210 D Loss: 0.6555 G Loss: 6.4507\n",
      "Epoch [1/1] Batch 1000/2210 D Loss: 0.5753 G Loss: 7.6771\n",
      "Epoch [1/1] Batch 1050/2210 D Loss: 0.1152 G Loss: 5.3634\n",
      "Epoch [1/1] Batch 1100/2210 D Loss: 0.0058 G Loss: 5.5484\n",
      "Epoch [1/1] Batch 1150/2210 D Loss: 0.0051 G Loss: 6.4319\n",
      "Epoch [1/1] Batch 1200/2210 D Loss: 0.0205 G Loss: 4.4391\n",
      "Epoch [1/1] Batch 1250/2210 D Loss: 0.0048 G Loss: 5.5707\n",
      "Epoch [1/1] Batch 1300/2210 D Loss: 0.0343 G Loss: 4.4860\n",
      "Epoch [1/1] Batch 1350/2210 D Loss: 0.4510 G Loss: 2.9959\n",
      "Epoch [1/1] Batch 1400/2210 D Loss: 0.0752 G Loss: 3.4875\n",
      "Epoch [1/1] Batch 1450/2210 D Loss: 0.0096 G Loss: 5.1204\n",
      "Epoch [1/1] Batch 1500/2210 D Loss: 0.1029 G Loss: 3.3599\n",
      "Epoch [1/1] Batch 1550/2210 D Loss: 1.0338 G Loss: 5.3869\n",
      "Epoch [1/1] Batch 1600/2210 D Loss: 0.0456 G Loss: 3.3516\n",
      "Epoch [1/1] Batch 1650/2210 D Loss: 0.0153 G Loss: 5.1824\n",
      "Epoch [1/1] Batch 1700/2210 D Loss: 0.0221 G Loss: 5.1931\n",
      "Epoch [1/1] Batch 1750/2210 D Loss: 0.0190 G Loss: 4.3612\n",
      "Epoch [1/1] Batch 1800/2210 D Loss: 0.0031 G Loss: 5.5940\n",
      "Epoch [1/1] Batch 1850/2210 D Loss: 0.0775 G Loss: 5.2434\n",
      "Epoch [1/1] Batch 1900/2210 D Loss: 0.0139 G Loss: 4.5145\n",
      "Epoch [1/1] Batch 1950/2210 D Loss: 0.1027 G Loss: 3.1417\n",
      "Epoch [1/1] Batch 2000/2210 D Loss: 0.0231 G Loss: 3.9793\n",
      "Epoch [1/1] Batch 2050/2210 D Loss: 0.0188 G Loss: 4.2260\n",
      "Epoch [1/1] Batch 2100/2210 D Loss: 0.6948 G Loss: 6.5301\n",
      "Epoch [1/1] Batch 2150/2210 D Loss: 0.8983 G Loss: 2.2193\n",
      "Epoch [1/1] Batch 2200/2210 D Loss: 0.1066 G Loss: 2.6317\n",
      "syn sample shape:  torch.Size([1, 1, 256, 256])\n",
      "Shape of the generated image:  (256, 256)\n",
      "Epoch [1/1] D Loss: 0.0219 G Loss: 4.0726\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\kamen\\\\Dev\\\\School\\\\H25\\\\IFT3710\\\\IFT3710-Advanced-Project-in-ML-AI\\\\data\\\\preprocessing_outputs\\\\unified_set\\\\labels\"\n",
    "z_dim = 256\n",
    "channels = 1\n",
    "model = GANModel(z_dim, channels)\n",
    "data = create_dataloader(path, 1, 256)\n",
    "trainer = Trainer(model, data, device=\"cuda\")\n",
    "trainer.train(epochs=1)\n",
    "evaluator = Evaluator(model, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call generators and create samples. The logic here is to create an ensemble of generators (proposed by Goodfellow). Choose later weights for better learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators chosen arbitrarely. Could have some sort of heuristic to chose generators.\n",
    "generators = [90, 86, 82, 67]\n",
    "for generator in generators: \n",
    "    model.load_state_dict(torch.load(f\"gan_256x256_epoch_{str(generator)}.pth\"))\n",
    "    syn_samples = evaluator.generate_samples(1000)\n",
    "    for i in range(syn_samples.shape[0]):\n",
    "        evaluator.save_sample_image(syn_samples[i], generator, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
